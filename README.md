# ExpenseAnalysis


Este repositorio contiene el c√≥digo y los recursos necesarios para trabajar con microdatos del Instituto Nacional de Estad√≠stica (INE) desde el a√±o 2006 hasta 2023, junto con otros indicadores como el IPC y la tasa de paro por comunidad aut√≥noma.

## üì• Paso 1: Recogida de Microdatos

1. Accede al siguiente enlace del INE para descargar los microdatos:
   üëâ [Encuesta de Presupuestos Familiares (EPF) - Resultados](https://www.ine.es/dyngs/INEbase/operacion.htm?c=Estadistica_C&cid=1254736176806&menu=resultados&idp=1254735976608#_tabs-1254736195147)

2. Para **cada a√±o desde 2006 hasta 2023**, descarga los microdatos disponibles (normalmente vienen en un archivo ZIP que contiene tres ficheros):

   - **Gastos**
   - **Hogar**
   - **Miembros del hogar**

3. Descomprime los archivos y organiza la informaci√≥n en carpetas siguiendo esta estructura:

```
data/
‚îú‚îÄ‚îÄ 2006/
‚îÇ ‚îú‚îÄ‚îÄ gastos_2006
‚îÇ ‚îú‚îÄ‚îÄ hogar_2006
‚îÇ ‚îî‚îÄ‚îÄ miembros_2006
‚îú‚îÄ‚îÄ 2007/
‚îÇ ‚îú‚îÄ‚îÄ ...
...
‚îî‚îÄ‚îÄ 2023/
```

---

## üìà Paso 2: Descargar datos complementarios

### üî∏ IPC por Comunidad y A√±o

1. Entra en el siguiente enlace:
üëâ [IPC por comunidad aut√≥noma y a√±o - INE](https://www.ine.es/jaxiT3/Tabla.htm?t=50913)

2. Filtra los datos para los a√±os 2006‚Äì2023 y **exporta el resultado como archivo CSV**.

3. Guarda el archivo en el directorio ra√≠z del proyecto con un nombre como: ipc_comunidades.csv


---

### üî∏ Tasa de Paro por Comunidad y A√±o

1. Accede a esta tabla:
üëâ [Tasa de paro por comunidad y a√±o - INE](https://www.ine.es/jaxiT3/Tabla.htm?t=4247)

2. Selecciona los a√±os 2006‚Äì2023 y exporta el CSV con los datos.

3. Guarda el archivo con un nombre como: tasa_paro_comunidades.csv



---

## üìö Otros datos

El resto de los datos utilizados ya est√°n incluidos directamente en el notebook de trabajo y no requieren descarga adicional.

---

## ‚úÖ Estructura esperada

```
ExpenseAnalysis/
  data/
    2006/
    2007/
    ...
    ipc_comunidades.csv
    tasa_paro_comunidades.csv
  notebooks/
    *.ipynb
  README.md
```

## üßÆ Orden de Ejecuci√≥n de Notebooks

Una vez descargados y organizados los datos, se deben ejecutar los notebooks en el siguiente orden para procesar toda la informaci√≥n y generar los datamarts necesarios.

---

### 1Ô∏è‚É£ Visualizaci√≥n y Recolecci√≥n de Datos de Entorno

**Notebook**: `notebooks/views/view_and_collect_data.ipynb`

Este notebook permite comprobar que los datos recolectados tienen un formato v√°lido. Adem√°s, se encarga de recoger los datos de entorno faltantes y generar los correspondientes archivos CSV que se utilizar√°n en pasos posteriores.

---

### 2Ô∏è‚É£ Procesamiento y Unificaci√≥n de Datos

**Notebook**: `notebooks/proceesing/proccess_data.ipynb`

Este notebook construye el **datalake principal**:

- Unifica la estructura de los microdatos de todos los a√±os en un √∫nico dataset coherente.
- Agrega los datos de entorno (IPC, tasa de paro, etc.).
- Agrupa la informaci√≥n por a√±o para facilitar el an√°lisis.


A continuaci√≥n se muestra la estructura del DataLake generada:

| Carpeta (A√±o) | Archivo                        | Descripci√≥n                                                                 |
|---------------|--------------------------------|-----------------------------------------------------------------------------|
| `2006`‚Äì`2023` | `family_expenses.tsv`          | Informaci√≥n detallada sobre los gastos familiares                          |
|               | `homes.tsv`                    | Informaci√≥n sociodemogr√°fica del hogar                                     |
|               | `external_indicators.tsv`      | Indicadores externos a√±adidos (IPC, tasa de paro, etc.) por comunidad y a√±o |

---


### 3Ô∏è‚É£ Agregaci√≥n por Categor√≠as de Gasto

**Notebook**: `notebooks/proceesing/proccess_codes.ipynb`

Este notebook transforma los datos econ√≥micos en distintos niveles de agregaci√≥n:

- A√±ade columnas con el gasto monetario agrupado por categor√≠as superiores.
- Genera **dos datamarts**:
  - Uno con agrupaci√≥n por la **categor√≠a de gasto m√°s alta**.
  - Otro con agrupaci√≥n por **subcategor√≠as**.

Esto es necesario porque los datos originales contienen el gasto clasificado √∫nicamente en el nivel m√°s bajo de codificaci√≥n.

---

### 4Ô∏è‚É£ Creaci√≥n del Datamart Final (Formato Picota)

**Notebook**: `notebooks/datamart_builder/create_datamart_picota.ipynb`

Este notebook genera el datamart final que se usar√° para el entrenamiento de modelos explicativos y estimativos.  
El formato resultante es compatible con **Picota**, una herramienta de an√°lisis de gasto y explicabilidad de modelos.

> üìä Este es el formato de entrada requerido por Picota para aplicar t√©cnicas avanzadas de machine learning sobre los datos procesados.



## üß† Modelo Explicativo

Una vez construido el datamart final, se procede a analizar qu√© variables explican el gasto en cada categor√≠a mediante distintos enfoques de an√°lisis de sensibilidad.

---

### 5Ô∏è‚É£ An√°lisis de Sensibilidad

Ejecutar los siguientes notebooks en orden:

1. **An√°lisis lineal de sensibilidad**  
   üìò `notebooks/sensitivity_analysis/sensitivity_analisys_advanced.ipynb`  
   Realiza un an√°lisis de sensibilidad utilizando regresi√≥n lineal para evaluar la influencia de cada variable en el gasto por categor√≠a.

2. **An√°lisis no lineal de sensibilidad**  
   üìò `notebooks/sensitivity_analysis/sensitivity_analisys_nolineal.ipynb`  
   Utiliza modelos no lineales (como redes neuronales u otros m√©todos avanzados) para detectar relaciones m√°s complejas entre las variables y el gasto.

---

### 6Ô∏è‚É£ Comparaci√≥n de Modelos

üìò `notebooks/research/linear_and_nolinear_comparison.ipynb`

Este notebook compara el rendimiento de los modelos explicativos obtenidos en los pasos anteriores:

- Muestra los valores de **R¬≤** de cada modelo por categor√≠a de gasto.
- Presenta los **coeficientes** (modelo lineal) y **importancias** (modelo no lineal).
- Permite identificar las variables que m√°s influyen en el gasto en cada categor√≠a.

> üéØ Esta etapa es clave para entender el comportamiento del gasto en los hogares y qu√© factores lo determinan, tanto desde una perspectiva lineal como no lineal.

## üîß Paso 7Ô∏è‚É£: Creaci√≥n del gemelo digital en Quassar/Picota

Tras construir y validar el datamart final en formato compatible con **Picota**, el siguiente paso es crear nuestro **gemelo digital** para modelizar el comportamiento de los hogares.

### ‚úçÔ∏è 7.1 Registro en Quassar y Picota

1Ô∏è‚É£ Accede a [Quassar](https://quassar.io/) y [Picota](https://picota.io/).  
2Ô∏è‚É£ Crea una cuenta gratuita o inicia sesi√≥n si ya tienes una.  
3Ô∏è‚É£ Desde el panel de usuario de **Picota**, crea un nuevo proyecto y selecciona como fuente de datos el datamart generado en el paso anterior.

---

### üîπ 7.2 Definir la `Reality` y el `DigitalSubject` en DSL

Usaremos el **DSL de Picota** (Domain-Specific Language) para definir formalmente nuestra `Reality Espa√±a` y el `DigitalSubject hogar`.

A continuaci√≥n, reproducir una estructura **como se muestra en la ilustraci√≥n `quassar_picota_subject.png`**:

```picota
Reality Espa√±a

Variable tasaCambioEurUsd is Numeric
Variable tipoInteres is Numeric

Subject hogar is Prototype(prefix = "hogar")
    Variable temperaturaMedia is Numeric
    Variable tasaParo is Numeric
    Variable inflacion is Numeric
    Variable ipc is Numeric
    Variable capitalProvincia is Boolean
    Variable tamanoMunicipio is Numeric
    Variable densidad is Numeric
    Variable superficie is Numeric
    Variable tipoCasa is Numeric
    Variable aguaCaliente is Boolean
    Variable calefaccion is Boolean
    Variable zonaResidencial is Boolean
    Variable regimenTenencia is Numeric
    Variable edadSp is Numeric
    Variable espanolSp is Boolean
    Variable educacionSuperiorSp is Boolean
    Variable numeroViviendasAdicionales is Numeric
    Variable ingresosNetos is Numeric
    Variable tasaAhorro is Numeric
    Variable gastoNoMonetario is Numeric
    Variable comidasTotales is Numeric
    Variable fuentePrincipalIngresos is Enumerated("pension" "asalariado" "autonomoYRenta")
    Variable gastoMonetario is Numeric Composite
        Components("productosAlimenticios11" "bebidasNoAlcoholicas12" "bebidasAlcoholicas21" "tabaco22" ... "remesas128")
    Variable miembros is Numeric Composite
        Components("ancianos" "adultos" "ninos")
        Components("masculinos" "femeninos")
        Components("ocupados" "noOcupados")
        Components("activos" "noActivos")
        Components("conIngresos" "sinIngresos")
        Components("estudiantes" "noEstudiantes")
```

### üîπ 7.3 Definir el `DigitalTwin`

A continuaci√≥n, se define el `DigitalTwin`, siguiendo el ejemplo de la ilustraci√≥n `quassar_picota_twin.png`:

```picota
DigitalTwin
    DigitalSubject
        subject = Espa√±a.hogar
        Resolution(scale = Hours)
        InferenceModel
            variable = Espa√±a.hogar.gastoMonetario
```

üî® **Una vez definido el `DigitalTwin`, a√∫n no est√° listo el gemelo digital:**

1Ô∏è‚É£ Luego, deber√°s pulsar el bot√≥n `Build in Picota` desde el editor de `Quassar`.  
2Ô∏è‚É£ En el paso siguiente, debes **comprimir todos los archivos `.tsv` ubicados dentro de la carpeta generada `/picotaData`** (‚ö†Ô∏è *no comprimir la carpeta completa, solo su contenido*).  
3Ô∏è‚É£ Despu√©s, en la interfaz de `Picota`, **subir ese archivo comprimido en la secci√≥n correspondiente y pulsar `Construir`**.

‚úÖ Al finalizar este proceso, tendr√°s el **gemelo digital listo para ejecutar estimaciones y an√°lisis avanzados sobre el gasto monetario de los hogares en Espa√±a**.

---

## 8Ô∏è‚É£ Preparar hogares para simulaci√≥n y ajustar impuestos

Una vez **entrenado el gemelo digital**, se deben ejecutar los siguientes pasos para preparar la simulaci√≥n fiscal:

### üîπ 8.1 Crear datamart de hogares simulados

üìì Ejecutar el notebook:  
`notebooks/create_datamart_irpf.ipynb`  

‚úÖ Esto generar√° los hogares con las datos necesarios para la simulaci√≥n fiscal.

---

### üîπ 8.2 Ajustar impuestos y crear datamart de tipos impositivos

üìì Ejecutar el notebook:  
`notebooks/create_datamart_indirect_taxes.ipynb`  

üîß Antes de ejecutarlo puedes **ajustar manualmente los tipos impositivos para reflejar la realidad fiscal deseada** (o bien dejar los valores por defecto).

‚úÖ Al finalizar este notebook, quedar√°n configurados los tipos de impuestos indirectos que se utilizar√°n en la simulaci√≥n (IVA, IGIC, IPSI).

---

---

## 9Ô∏è‚É£ Configurar API y ejecutar la simulaci√≥n fiscal

### üîπ 9.1 Copiar API ID del gemelo digital

Una vez construido el gemelo digital en Picota:

- Accede al gemelo digital en Picota y copia el valor de `API_ID` que se ha generado.

---

### üîπ 9.2 Configurar API en el notebook de simulaci√≥n

üìì Abre el notebook:  
`notebooks/irpf_simulation.ipynb`

üîß Sustituye la l√≠nea:

```python
API_ID = 'TU_API_ID'
```

por:

```python
API_ID = 'el_api_id_de_tu_gemelo'
```

### üîπ 9.3 Ejecutar simulaci√≥n

‚úÖ Ejecuta el notebook completo `notebooks/irpf_simulation.ipynb` para simular distintos escenarios de deducci√≥n fiscal.

üìù **Opcional:**  
Puedes ajustar las **probabilidades de nacimiento en cada escenario** y el **importe a deducir** para personalizar los escenarios seg√∫n tus necesidades antes de ejecutar la simulaci√≥n.
