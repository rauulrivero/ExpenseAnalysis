# ExpenseAnalysis


Este repositorio contiene el cÃ³digo y los recursos necesarios para trabajar con microdatos del Instituto Nacional de EstadÃ­stica (INE) desde el aÃ±o 2006 hasta 2023, junto con otros indicadores como el IPC y la tasa de paro por comunidad autÃ³noma.

## ğŸ“¥ Paso 1: Recogida de Microdatos

1. Accede al siguiente enlace del INE para descargar los microdatos:
   ğŸ‘‰ [Encuesta de Presupuestos Familiares (EPF) - Resultados](https://www.ine.es/dyngs/INEbase/operacion.htm?c=Estadistica_C&cid=1254736176806&menu=resultados&idp=1254735976608#_tabs-1254736195147)

2. Para **cada aÃ±o desde 2006 hasta 2023**, descarga los microdatos disponibles (normalmente vienen en un archivo ZIP que contiene tres ficheros):

   - **Gastos**
   - **Hogar**
   - **Miembros del hogar**

3. Descomprime los archivos y organiza la informaciÃ³n en carpetas siguiendo esta estructura:

```
data/
â”œâ”€â”€ 2006/
â”‚ â”œâ”€â”€ gastos_2006
â”‚ â”œâ”€â”€ hogar_2006
â”‚ â””â”€â”€ miembros_2006
â”œâ”€â”€ 2007/
â”‚ â”œâ”€â”€ ...
...
â””â”€â”€ 2023/
```

---

## ğŸ“ˆ Paso 2: Descargar datos complementarios

### ğŸ”¸ IPC por Comunidad y AÃ±o

1. Entra en el siguiente enlace:
ğŸ‘‰ [IPC por comunidad autÃ³noma y aÃ±o - INE](https://www.ine.es/jaxiT3/Tabla.htm?t=50913)

2. Filtra los datos para los aÃ±os 2006â€“2023 y **exporta el resultado como archivo CSV**.

3. Guarda el archivo en el directorio raÃ­z del proyecto con un nombre como: ipc_comunidades.csv


---

### ğŸ”¸ Tasa de Paro por Comunidad y AÃ±o

1. Accede a esta tabla:
ğŸ‘‰ [Tasa de paro por comunidad y aÃ±o - INE](https://www.ine.es/jaxiT3/Tabla.htm?t=4247)

2. Selecciona los aÃ±os 2006â€“2023 y exporta el CSV con los datos.

3. Guarda el archivo con un nombre como: tasa_paro_comunidades.csv



---

## ğŸ“š Otros datos

El resto de los datos utilizados ya estÃ¡n incluidos directamente en el notebook de trabajo y no requieren descarga adicional.

---

## âœ… Estructura esperada

```
ExpenseAnalysis/
  data/
    2006/
    2007/
    ...
    ipc_comunidades.csv
    tasa_paro_comunidades.csv
  notebooks/
    *.ipynb
  README.md
```

## ğŸ§® Orden de EjecuciÃ³n de Notebooks

Una vez descargados y organizados los datos, se deben ejecutar los notebooks en el siguiente orden para procesar toda la informaciÃ³n y generar los datamarts necesarios.

---

### 1ï¸âƒ£ VisualizaciÃ³n y RecolecciÃ³n de Datos de Entorno

**Notebook**: `notebooks/views/view_and_collect_data.ipynb`

Este notebook permite comprobar que los datos recolectados tienen un formato vÃ¡lido. AdemÃ¡s, se encarga de recoger los datos de entorno faltantes y generar los correspondientes archivos CSV que se utilizarÃ¡n en pasos posteriores.

---

### 2ï¸âƒ£ Procesamiento y UnificaciÃ³n de Datos

**Notebook**: `notebooks/proceesing/proccess_data.ipynb`

Este notebook construye el **datalake principal**:

- Unifica la estructura de los microdatos de todos los aÃ±os en un Ãºnico dataset coherente.
- Agrega los datos de entorno (IPC, tasa de paro, etc.).
- Agrupa la informaciÃ³n por aÃ±o para facilitar el anÃ¡lisis.


A continuaciÃ³n se muestra la estructura del DataLake generada:

| Carpeta (AÃ±o) | Archivo                        | DescripciÃ³n                                                                 |
|---------------|--------------------------------|-----------------------------------------------------------------------------|
| `2006`â€“`2023` | `family_expenses.tsv`          | InformaciÃ³n detallada sobre los gastos familiares                          |
|               | `homes.tsv`                    | InformaciÃ³n sociodemogrÃ¡fica del hogar                                     |
|               | `external_indicators.tsv`      | Indicadores externos aÃ±adidos (IPC, tasa de paro, etc.) por comunidad y aÃ±o |

---


### 3ï¸âƒ£ AgregaciÃ³n por CategorÃ­as de Gasto

**Notebook**: `notebooks/proceesing/proccess_codes.ipynb`

Este notebook transforma los datos econÃ³micos en distintos niveles de agregaciÃ³n:

- AÃ±ade columnas con el gasto monetario agrupado por categorÃ­as superiores.
- Genera **dos datamarts**:
  - Uno con agrupaciÃ³n por la **categorÃ­a de gasto mÃ¡s alta**.
  - Otro con agrupaciÃ³n por **subcategorÃ­as**.

Esto es necesario porque los datos originales contienen el gasto clasificado Ãºnicamente en el nivel mÃ¡s bajo de codificaciÃ³n.

---

### 4ï¸âƒ£ CreaciÃ³n del Datamart Final (Formato Picota)

**Notebook**: `notebooks/datamart_builder/create_datamart_picota.ipynb`

Este notebook genera el datamart final que se usarÃ¡ para el entrenamiento de modelos explicativos y estimativos.  
El formato resultante es compatible con **Picota**, una herramienta de anÃ¡lisis de gasto y explicabilidad de modelos.

> ğŸ“Š Este es el formato de entrada requerido por Picota para aplicar tÃ©cnicas avanzadas de machine learning sobre los datos procesados.



## ğŸ§  Modelo Explicativo

Una vez construido el datamart final, se procede a analizar quÃ© variables explican el gasto en cada categorÃ­a mediante distintos enfoques de anÃ¡lisis de sensibilidad.

---

### 5ï¸âƒ£ AnÃ¡lisis de Sensibilidad

Ejecutar los siguientes notebooks en orden:

1. **AnÃ¡lisis lineal de sensibilidad**  
   ğŸ“˜ `notebooks/sensitivity_analysis/sensitivity_analisys_advanced.ipynb`  
   Realiza un anÃ¡lisis de sensibilidad utilizando regresiÃ³n lineal para evaluar la influencia de cada variable en el gasto por categorÃ­a.

2. **AnÃ¡lisis no lineal de sensibilidad**  
   ğŸ“˜ `notebooks/sensitivity_analysis/sensitivity_analisys_nolineal.ipynb`  
   Utiliza modelos no lineales (como redes neuronales u otros mÃ©todos avanzados) para detectar relaciones mÃ¡s complejas entre las variables y el gasto.

---

### 6ï¸âƒ£ ComparaciÃ³n de Modelos

ğŸ“˜ `notebooks/research/linear_and_nolinear_comparison.ipynb`

Este notebook compara el rendimiento de los modelos explicativos obtenidos en los pasos anteriores:

- Muestra los valores de **RÂ²** de cada modelo por categorÃ­a de gasto.
- Presenta los **coeficientes** (modelo lineal) y **importancias** (modelo no lineal).
- Permite identificar las variables que mÃ¡s influyen en el gasto en cada categorÃ­a.

> ğŸ¯ Esta etapa es clave para entender el comportamiento del gasto en los hogares y quÃ© factores lo determinan, tanto desde una perspectiva lineal como no lineal.

## ğŸ”§ Paso 7ï¸âƒ£: CreaciÃ³n del gemelo digital en Quassar/Picota

Tras construir y validar el datamart final en formato compatible con **Picota**, el siguiente paso es crear nuestro **gemelo digital** para modelizar el comportamiento de los hogares.

### âœï¸ 7.1 Registro en Quassar y Picota

1ï¸âƒ£ Accede a [Quassar](https://quassar.io/) y [Picota](https://picota.io/).  
2ï¸âƒ£ Crea una cuenta gratuita o inicia sesiÃ³n si ya tienes una.  
3ï¸âƒ£ Desde el panel de usuario de **Picota**, crea un nuevo proyecto y selecciona como fuente de datos el datamart generado en el paso anterior.

---

### ğŸ”¹ 7.2 Definir la `Reality` y el `DigitalSubject` en DSL

Usaremos el **DSL de Picota** (Domain-Specific Language) para definir formalmente nuestra `Reality EspaÃ±a` y el `DigitalSubject hogar`.

A continuaciÃ³n, reproducir una estructura **como se muestra en la ilustraciÃ³n `quassar_picota_subject.png`**:

```picota
Reality EspaÃ±a

Variable tasaCambioEurUsd is Numeric
Variable tipoInteres is Numeric

Subject hogar is Prototype(prefix = "hogar")
    Variable temperaturaMedia is Numeric
    Variable tasaParo is Numeric
    Variable inflacion is Numeric
    Variable ipc is Numeric
    Variable capitalProvincia is Boolean
    Variable tamanoMunicipio is Numeric
    Variable densidad is Numeric
    Variable superficie is Numeric
    Variable tipoCasa is Numeric
    Variable aguaCaliente is Boolean
    Variable calefaccion is Boolean
    Variable zonaResidencial is Boolean
    Variable regimenTenencia is Numeric
    Variable edadSp is Numeric
    Variable espanolSp is Boolean
    Variable educacionSuperiorSp is Boolean
    Variable numeroViviendasAdicionales is Numeric
    Variable ingresosNetos is Numeric
    Variable tasaAhorro is Numeric
    Variable gastoNoMonetario is Numeric
    Variable comidasTotales is Numeric
    Variable fuentePrincipalIngresos is Enumerated("pension" "asalariado" "autonomoYRenta")
    Variable gastoMonetario is Numeric Composite
        Components("productosAlimenticios11" "bebidasNoAlcoholicas12" "bebidasAlcoholicas21" "tabaco22" ... "remesas128")
    Variable miembros is Numeric Composite
        Components("ancianos" "adultos" "ninos")
        Components("masculinos" "femeninos")
        Components("ocupados" "noOcupados")
        Components("activos" "noActivos")
        Components("conIngresos" "sinIngresos")
        Components("estudiantes" "noEstudiantes")
```

### ğŸ”¹ 7.3 Definir el `DigitalTwin`

A continuaciÃ³n, se define el `DigitalTwin`, siguiendo el ejemplo de la ilustraciÃ³n `quassar_picota_twin.png`:

```picota
DigitalTwin
    DigitalSubject
        subject = EspaÃ±a.hogar
        Resolution(scale = Hours)
        InferenceModel
            variable = EspaÃ±a.hogar.gastoMonetario
```

ğŸ”¨ **Una vez definido el `DigitalTwin`, aÃºn no estÃ¡ listo el gemelo digital:**

1ï¸âƒ£ Luego, deberÃ¡s pulsar el botÃ³n `Build in Picota` desde el editor de `Quassar`.  
2ï¸âƒ£ En el paso siguiente, debes **comprimir todos los archivos `.tsv` ubicados dentro de la carpeta generada `/picotaData`** (âš ï¸ *no comprimir la carpeta completa, solo su contenido*).  
3ï¸âƒ£ DespuÃ©s, en la interfaz de `Picota`, **subir ese archivo comprimido en la secciÃ³n correspondiente y pulsar `Construir`**.

âœ… Al finalizar este proceso, tendrÃ¡s el **gemelo digital listo para ejecutar estimaciones y anÃ¡lisis avanzados sobre el gasto monetario de los hogares en EspaÃ±a**.

---

## 8ï¸âƒ£ Preparar hogares para simulaciÃ³n y ajustar impuestos

Una vez **entrenado el gemelo digital**, se deben ejecutar los siguientes pasos para preparar la simulaciÃ³n fiscal:

### ğŸ”¹ 8.1 Crear datamart de hogares simulados

ğŸ““ Ejecutar el notebook:  
`notebooks/create_datamart_irpf.ipynb`  

âœ… Esto generarÃ¡ los hogares con las datos necesarios para la simulaciÃ³n fiscal.

---

### ğŸ”¹ 8.2 Ajustar impuestos y crear datamart de tipos impositivos

ğŸ““ Ejecutar el notebook:  
`notebooks/create_datamart_indirect_taxes.ipynb`  

ğŸ”§ Antes de ejecutarlo puedes **ajustar manualmente los tipos impositivos para reflejar la realidad fiscal deseada** (o bien dejar los valores por defecto).

âœ… Al finalizar este notebook, quedarÃ¡n configurados los tipos de impuestos indirectos que se utilizarÃ¡n en la simulaciÃ³n (IVA, IGIC, IPSI).

---

---

## 9ï¸âƒ£ Configurar API y ejecutar la simulaciÃ³n fiscal

### ğŸ”¹ 9.1 Copiar API ID del gemelo digital

Una vez construido el gemelo digital en Picota:

- Accede al gemelo digital en Picota y copia el valor de `API_ID` que se ha generado.

---

### ğŸ”¹ 9.2 Configurar API en el notebook de simulaciÃ³n

ğŸ““ Abre el notebook:  
`notebooks/irpf_simulation.ipynb`

ğŸ”§ Sustituye la lÃ­nea:

```python
API_ID = 'TU_API_ID'
```

por:

```python
API_ID = 'el_api_id_de_tu_gemelo'
```

### ğŸ”¹ 9.3 Ejecutar simulaciÃ³n

âœ… Ejecuta el notebook completo `notebooks/irpf_simulation.ipynb` para simular distintos escenarios de deducciÃ³n fiscal.

ğŸ“ **Opcional:**  
Puedes ajustar las **probabilidades de nacimiento en cada escenario** y el **importe a deducir** para personalizar los escenarios segÃºn tus necesidades antes de ejecutar la simulaciÃ³n.
